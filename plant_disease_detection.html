<div class='markdown'><p># Load and prepare the dataset</p></div>
<div class='code'><pre><code>!pip install tensorflow==2.15</code></pre></div>
<div class='code'><pre><code>import tensorflow as tf
import tensorflow_datasets as tfds
print(tf.version.VERSION)

# Check for available GPUs
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    print(f"GPUs are available: {gpus}")
else:
    print("No GPUs found.")
</code></pre></div>
<div class='code'><pre><code>import tensorflow as tf
import tensorflow_datasets as tfds

# Load the dataset and split into train (70%), val (20%), and test (10%)
splits = ['train[:70%]', 'train[70%:90%]', 'train[90%:]']
(train_ds, val_ds, test_ds), info = tfds.load('plant_village', with_info=True, as_supervised=True, split=splits)

# Define image size and batch size
IMG_SIZE = 224
BATCH_SIZE = 64

# # Data augmentation function
# def augment(image, label):
#     image = tf.image.random_flip_left_right(image)
#     image = tf.image.random_flip_up_down(image)
#     image = tf.image.random_brightness(image, max_delta=0.2)
#     image = tf.image.random_contrast(image, lower=0.8, upper=1.2)
#     image = tf.image.random_saturation(image, lower=0.8, upper=1.2)
#     image = tf.image.random_hue(image, max_delta=0.2)
#     image = tf.image.random_crop(image, size=[IMG_SIZE, IMG_SIZE, 3])
#     return image, label

# Preprocessing function
def preprocess(image, label):
    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])
    image = tf.cast(image, tf.float32) / 255.0
    return image, label

# Apply augmentation only to the training dataset
# train_ds = train_ds.map(augment).map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
train_ds = train_ds.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

# Apply preprocessing to validation and test datasets
val_ds = val_ds.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
test_ds = test_ds.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

# Print dataset information
print(info)</code></pre></div>
<div class='code'><pre><code>import matplotlib.pyplot as plt

# Function to display a batch of images and their labels
def visualize_sample_data(dataset, class_names, sample_size=9):
    plt.figure(figsize=(10, 10))
    
    for images, labels in dataset.take(1):
        for i in range(sample_size):
            ax = plt.subplot(3, 3, i + 1)
            plt.imshow(images[i].numpy())
            plt.title(class_names[labels[i].numpy()])
            plt.axis("off")
    plt.show()

# Retrieve class names
class_names = info.features['label'].names

# Visualize a sample of 9 images from the train dataset
visualize_sample_data(train_ds, class_names)

# Print class names with their corresponding indices
for index, class_name in enumerate(class_names):
    print(f'Class index: {index}, Class name: {class_name}')</code></pre></div>
<div class='markdown'><p># Build and train model</p></div>
<div class='code'><pre><code># Load the EfficientNetB3 base model
base_model = tf.keras.applications.MobileNetV2(input_shape=(IMG_SIZE, IMG_SIZE, 3),
                                                  include_top=False,
                                                  weights='imagenet')

base_model.trainable = False  # Freeze the base model

# Define the model using Functional API
inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))
x = base_model(inputs, training=False)  # Ensure base_model runs in inference mode
x = tf.keras.layers.GlobalAveragePooling2D()(x)
outputs = tf.keras.layers.Dense(38, activation='softmax')(x)

# Build the model
model = tf.keras.Model(inputs, outputs)

# print summary
model.summary()</code></pre></div>
<div class='code'><pre><code># Compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Define EarlyStopping callback
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=50,  # Number of epochs to wait for improvement
    restore_best_weights=True,
    verbose=1
)

# Define ModelCheckpoint callback for both best model and latest model
model_checkpoint_best = tf.keras.callbacks.ModelCheckpoint(
    'best_model.keras',
    monitor='val_accuracy',
    save_best_only=True,
    mode='max',
    verbose=1
)

model_checkpoint_latest = tf.keras.callbacks.ModelCheckpoint(
    'latest_model.keras',
    save_weights_only=True,
    mode='auto',
    verbose=1
)

# Define LearningRateScheduler callback with exponential decay
def scheduler(epoch, lr):
    if epoch < 50:
        return lr
    else:
        return lr * tf.math.exp(-0.1)

lr_scheduler = tf.keras.callbacks.LearningRateScheduler(
    scheduler,
    verbose=1
)

# # Define TensorBoard callback for monitoring
# tensorboard = tf.keras.callbacks.TensorBoard(
#     log_dir='./logs',
#     histogram_freq=1,
#     write_graph=True,
#     write_images=False,
#     update_freq='epoch'
# )

# Train the model with the defined callbacks
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=250,
    callbacks=[early_stopping, model_checkpoint_best, model_checkpoint_latest, lr_scheduler]
)

# Save the entire model as a `.keras` zip archive
model.save('final_model.keras')
</code></pre></div>
<div class='code'><pre><code>import matplotlib.pyplot as plt

# Plot training and validation accuracy and loss
def plot_history(history):
    plt.figure(figsize=(12, 5))

    # Plot accuracy
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.title('Accuracy')

    # Plot loss
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.title('Loss')

    plt.show()

plot_history(history)</code></pre></div>
<div class='markdown'><p># Convert model to tflite</p></div>
<div class='code'><pre><code>import tensorflow as tf

# Load the .keras model
loaded_model = tf.keras.models.load_model('final_model.keras')

# Convert the model to TensorFlow Lite
converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)
tflite_model = converter.convert()

# Save the TFLite model to the working directory
save_path = 'plant_disease_model.tflite'
try:
    with open(save_path, 'wb') as f:
        f.write(tflite_model)
    print(f"Model successfully saved to {save_path}")
except Exception as e:
    print(f"Failed to save the model: {e}")
</code></pre></div>
<div class='code'><pre><code># import tensorflow as tf

# # Load the .keras model
# loaded_model = tf.keras.models.load_model('final_model.keras')

# # Convert the model to TensorFlow Lite with Float16 quantization
# converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)

# # Set optimizations to default (enables quantization)
# converter.optimizations = [tf.lite.Optimize.DEFAULT]

# # Specify the Float16 quantization
# converter.target_spec.supported_types = [tf.float16]

# # Convert the model
# tflite_model = converter.convert()

# # Save the TFLite model to the working directory
# save_path = 'plant_disease_model_float16.tflite'
# try:
#     with open(save_path, 'wb') as f:
#         f.write(tflite_model)
#     print(f"Float16 quantized model successfully saved to {save_path}")
# except Exception as e:
#     print(f"Failed to save the quantized model: {e}")
</code></pre></div>
<div class='markdown'><p># Evaluate the tflite model</p></div>
<div class='code'><pre><code>import numpy as np
import tensorflow as tf
from PIL import Image

# Load TFLite model and allocate tensors
interpreter = tf.lite.Interpreter(model_path='plant_disease_model.tflite')
interpreter.allocate_tensors()

# Get input and output tensor details
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

print(input_details)
print(output_details)

def evaluate_model(ds):
    correct = 0
    total = 0

    for images, labels in ds:
        # Iterate through the batch
        for i in range(len(images)):
            # Convert the image to PIL format for preprocessing
            image = images[i].numpy().astype(np.float32)
            image = np.expand_dims(image, axis=0)
            
            label = labels[i].numpy()
            
            # Set the input tensor
            interpreter.set_tensor(input_details[0]['index'], image)
            
            # Run inference
            interpreter.invoke()
            
            # Get the result
            output_data = interpreter.get_tensor(output_details[0]['index'])
            prediction_idx = np.argmax(output_data, axis=1)[0]
            
            # print(f"Prediction: {prediction_idx}, Actual: {label}")
            
            if prediction_idx == label:
                correct += 1
            total += 1
    
    # Calculate accuracy
    accuracy = correct / total
    print(f"Accuracy: {accuracy * 100:.2f}%")

evaluate_model(test_ds)
</code></pre></div>
<div class='markdown'><p># Run Inference</p></div>
<div class='code'><pre><code>import numpy as np
import tensorflow as tf
from PIL import Image

# Load the .keras model
model = tf.keras.models.load_model('final_model.keras')

# Load TFLite model and allocate tensors
interpreter = tf.lite.Interpreter(model_path='plant_disease_model.tflite')
interpreter.allocate_tensors()

# Get input and output tensor details
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

def preprocess_image(image_path, img_size=224):
    # Load and preprocess the image
    image = Image.open(image_path)
    image = image.resize((img_size, img_size))
    image = np.array(image).astype(np.float32) / 255.0
    # Add batch dimension
    image = np.expand_dims(image, axis=0)
    return image

def predict_tflite(image_path):
    # Preprocess the image
    image = preprocess_image(image_path)
    
    # Set the tensor for input
    interpreter.set_tensor(input_details[0]['index'], image)
    
    # Run inference
    interpreter.invoke()
    
    # Get the result
    output_data = interpreter.get_tensor(output_details[0]['index'])
    prediction = np.argmax(output_data, axis=1)
    
    return prediction

def predict_float(image_path):
    # Preprocess the image
    image = preprocess_image(image_path)
    
    # Run inference
    output_data = model.predict(image)
    
    # Get the result
    prediction = np.argmax(output_data, axis=1)
    
    return prediction</code></pre></div>
<div class='code'><pre><code># Example usage
image_path = '/kaggle/input/plantvillage-dataset/color/Orange___Haunglongbing_(Citrus_greening)/000945ae-3cf5-48c2-86a2-a3f1e777f2c7___CREC_HLB 7640.JPG'  # Replace with your image path
result = predict_tflite(image_path)
print(f'Predicted class: {result}')

# Example usage:
result = predict_float(image_path)
print("Predicted class:", result)</code></pre></div>